{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " From the given dataset, extract the input data(feature) that is most suitable for training\n",
    " and the corresponding result(label) column\n",
    " \n",
    " These two columns are simply written in new file with little processing\n",
    " Initial data is still untouched\n",
    " \n",
    " The features that are used at application level and that convey less meaning are neglected\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import ast, csv, json\n",
    "\n",
    "# variables to store the feature and label\n",
    "data_list =[]\n",
    "label_list = []\n",
    "\n",
    "dataset = pd.read_csv(\"NLP.csv\")\n",
    "for data,label in zip(dataset[\"data\"],dataset[\"label\"]):\n",
    "    # encode the data in ascii to avoid confusing character(like smileys/camera etc..) introduced in Unicode\n",
    "    # decode that back to restore the string representation\n",
    "    # if the data or label is empty, it is of no use. Hence, remove them too\n",
    "    # Further, strip the data. Whitespaces does not mean much\n",
    "    formatted_data = ast.literal_eval(data)[\"data\"].encode('ascii', 'ignore').decode('utf-8')\n",
    "    if(formatted_data.strip() != \"\" and label.strip() != \"\"):\n",
    "        data_list.append(formatted_data)\n",
    "        label_list.append(label)\n",
    "\n",
    "# Write those varibales(that undergone little formatting) into a CSV file\n",
    "with open('reqColsFile.csv', 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL,delimiter=',')\n",
    "    wr.writerow([\"text\",\"label\"])\n",
    "    wr.writerows(zip(data_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " As most of the common data are classified imperfect, use regex operations to actually (clean)convey proper \n",
    " meaning for training purposes.\n",
    " \n",
    " The CSV file extracted from the previous stage is used for cleaning purposes.\n",
    " The cleaned data is written in another CSV file for further processing\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import re, csv\n",
    "\n",
    "reqColsFile = pd.read_csv(\"reqColsFile.csv\")\n",
    "\n",
    "#hi, hello, good morning, whereWhich, thank you, okayOK, sorRy\n",
    "\n",
    "for index, colRow in reqColsFile.iterrows():\n",
    "    # The string representation is stored in a variable to avoid processing colRow frequently\n",
    "    # especially in OR conditions that are involved\n",
    "    colRowText = str(colRow[\"text\"])\n",
    "    \n",
    "    if re.match(\"[\\s]*ha*[i]+\", colRowText, re.I) or re.match(\"^[\\s]*h.e*[l]+o+\", colRowText, re.I):\n",
    "        colRow[\"label\"] = \"greeting\"\n",
    "        \n",
    "    elif re.match(\"[\\s]*g[oud\\s]*m[orning]*\", colRowText, re.I):# [\\s]*go*u*d\\s*m[orning]*\n",
    "        colRow[\"label\"] = \"greeting\"\n",
    "        \n",
    "    elif(re.match(\"[\\s]*t[qhanks\\syou]+\", colRowText, re.I)):\n",
    "        colRow[\"label\"] = \"greeting\"\n",
    "        \n",
    "    elif(re.match(\"[\\s]*wh[ere]+\", colRowText, re.I) or re.match(\"[\\s]*wr\\\\b\", colRowText, re.I)):\n",
    "        colRow[\"label\"] = \"location\"\n",
    "        \n",
    "    elif(re.match(\"[\\s]*s[or]*ry\", colRowText, re.I)):\n",
    "        colRow[\"label\"] = \"dontMeetRequirements\"\n",
    "\n",
    "    elif(re.match(\"[\\s]*o[kieay]+\", colRowText, re.I) or re.match(\"[\\s]*k\\\\b\", colRowText, re.I)):\n",
    "        colRow[\"label\"] = \"greeting\"\n",
    "\n",
    "# The result is written into a CSV, though handling differs from the previous stage\n",
    "reqColsFile.to_csv(\"intentClassifiedFile.csv\", sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " The rasa_nlu classifier accepts training data in either json format or in the markdown format\n",
    " With the available data, json is easy to be constructed\n",
    " \n",
    " Hence, with the pre-processed data, json file is generated as required\n",
    "\"\"\"\n",
    "import csv, json\n",
    "\n",
    "csvfile = open('intentClassifiedFile.csv', 'r')\n",
    "\n",
    "common_examples = []\n",
    "\n",
    "fieldnames = (\"text\",\"intent\")\n",
    "reader = csv.DictReader(csvfile, fieldnames)\n",
    "\n",
    "for row in reader:\n",
    "    common_examples.append(row)\n",
    "    \n",
    "del common_examples[0] # remove header row\n",
    "\n",
    "# construct the required json structure\n",
    "rasa_nlu_data = {\"common_examples\" : common_examples}\n",
    "json_data = {\"rasa_nlu_data\" : rasa_nlu_data}\n",
    "\n",
    "# The result file that will be fed into rasa for training\n",
    "with open('intentClassifiedFile.json', 'w') as fp:\n",
    "    json.dump(json_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m rasa_nlu.train -c nlu_config.yml --data intentClassifiedFile.json -o models --fixed_model_name intentClassifier --project current --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This is executed after a model is successfully generated.\n",
    " With random data inputs, the model is tested.\n",
    " \n",
    " The expected intents are classified as expected with sample data\n",
    "\"\"\"\n",
    "\n",
    "from rasa_nlu.model import Interpreter\n",
    "import json\n",
    "interpreter = Interpreter.load(\"./models/current/intentClassifier\")\n",
    "\n",
    "# Test with sample data\n",
    "print(json.dumps(interpreter.parse(\"Where are you from?\")[\"intent\"], indent=2))\n",
    "print(json.dumps(interpreter.parse(\"Gd mrng babie\")[\"intent\"], indent=2))\n",
    "print(json.dumps(interpreter.parse(\"Tq very much for ur hlp\")[\"intent\"], indent=2))\n",
    "print(json.dumps(interpreter.parse(\"sry, I can't help\")[\"intent\"], indent=2))\n",
    "print(json.dumps(interpreter.parse(\"hallo\")[\"intent\"], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
